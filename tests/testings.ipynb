{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Rm7WWX00ypi"
   },
   "source": [
    "!pip install ultralytics"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import cv2\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "logging.getLogger('ultralytics').setLevel(logging.WARNING)"
   ],
   "metadata": {
    "id": "yDR5X6n-04jZ"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Yolo tracking"
   ],
   "metadata": {
    "id": "xHvxlBNy1G7_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path_to_video = \"cut_output_0.mp4\"\n",
    "detection_model = YOLO('tracker.pt')\n",
    "video = cv2.VideoCapture(path_to_video)\n",
    "\n",
    "# Настройка выходного видео\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "\n",
    "output_file = f'Yolo_tracker.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_file, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "# Директория для сохранения вырезанных объектов\n",
    "\n",
    "start = time.time()\n",
    "frame_count = 0\n",
    "while True:\n",
    "\n",
    "    # Выводим каждый 20 кадр\n",
    "    if frame_count % 20 == 0:\n",
    "        print(f'Frame {frame_count}')\n",
    "\n",
    "    frame_count += 1\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Применяем модель YOLO для детекции объектов\n",
    "    results = detection_model.track(frame, persist=True, conf=0.3)\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Записываем кадр в выходное видео\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"\\nСреднее время обработки одного кадра - {round((end - start) / frame_count, 4)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b09a-T5Q1KEw",
    "outputId": "55c24dbf-92d0-4ad2-b250-c5e6ccb5dada"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Yolo classification"
   ],
   "metadata": {
    "id": "gdHKfA2s3B8r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_img = [\n",
    "   \"apple_test_1.png\",\n",
    "   \"apple_test_2.png\",\n",
    "   \"apple_test_3.png\",\n",
    "   \"apple_test_4.png\",\n",
    "   \"apple_test_5.png\",\n",
    "]"
   ],
   "metadata": {
    "id": "3R7rIi_R3ahI"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "classification_model = YOLO('classification.pt')\n",
    "\n",
    "for img_path in test_img:\n",
    "    results = classification_model(img_path)\n",
    "\n",
    "    annotated_img = results[0].plot()\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LYC0zf8Y2Z_N",
    "outputId": "c5b802e8-4050-479b-df2c-613c701f0eea"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Full pipeline"
   ],
   "metadata": {
    "id": "QdhKbR5T6BfP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Подключаем гугл диск\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "Xoau7vfw6TDY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def draw_custom_annotations(frame, results, tracker_d, save_dir, frame_count):\n",
    "    output = []\n",
    "    for obj in results[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, obj.xyxy[0].tolist())\n",
    "\n",
    "        D = max(abs(x2 - x1), abs(y2 - y1))\n",
    "        track_obj = obj.id\n",
    "        if not track_obj is None:\n",
    "            track_id = track_obj.item()\n",
    "            cropped_object = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Классифицируем\n",
    "            class_results = classification_model.predict(cropped_object, conf=0.25)\n",
    "            class_label = class_results[0].names[np.argmax(class_results[0].probs.data).item()]\n",
    "            probs =  max(class_results[0].probs.data).item()\n",
    "\n",
    "            # Установите нужный текст для аннотации\n",
    "            custom_text = f'Id {track_id} {class_label} {round(probs, 2)} D={round(D, 2)}'\n",
    "\n",
    "            path_to_save = f'{save_dir}/apple_{track_id}'\n",
    "            if track_id not in tracker_d:\n",
    "                tracker_d[track_id] = {\n",
    "                    'general': {\n",
    "                        'count': 0,\n",
    "                        'sum_bad': 0,\n",
    "                        'sum_D': 0,\n",
    "                        'sum_median_h': 0,\n",
    "                    },\n",
    "                    'history': []\n",
    "                }\n",
    "                os.makedirs(path_to_save, exist_ok=True)\n",
    "\n",
    "            object_filename = os.path.join(path_to_save, f'id_{track_id}_label_{class_label}_frame_{frame_count}.jpg')\n",
    "            cv2.imwrite(object_filename, cropped_object)\n",
    "\n",
    "\n",
    "            hsv_frame = cv2.cvtColor(cropped_object, cv2.COLOR_BGR2HSV)\n",
    "            h_channel, s_channel, v_channel = cv2.split(hsv_frame)\n",
    "\n",
    "            # Вычисление медианы для каждого канала\n",
    "            median_h = np.median(h_channel)\n",
    "            median_s = np.median(s_channel)\n",
    "            median_v = np.median(v_channel)\n",
    "\n",
    "            tracker_d[track_id]['history'].append({\n",
    "                'label': class_label,\n",
    "                'prob': probs,\n",
    "                'D': round(D, 2),\n",
    "                'x1': x1,\n",
    "                'x2': x2,\n",
    "                'y1': y1,\n",
    "                'y2': y2,\n",
    "                'median_h': median_h,\n",
    "                'median_s': median_s,\n",
    "                'median_v': median_v\n",
    "            })\n",
    "            tracker_d[track_id]['general']['count'] += 1\n",
    "            tracker_d[track_id]['general']['sum_bad'] += int(class_label != 'good')\n",
    "            tracker_d[track_id]['general']['sum_D'] += round(D, 2)\n",
    "            tracker_d[track_id]['general']['sum_median_h'] += median_h\n",
    "\n",
    "            if y2 < 30:\n",
    "                if x2 > 700:\n",
    "                    tracker_d[track_id]['general']['line'] = 1\n",
    "                else:\n",
    "                    tracker_d[track_id]['general']['line'] = 2\n",
    "                output.append(track_id)\n",
    "\n",
    "            # Определите цвет и шрифт\n",
    "            if class_label == \"good\":\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                color = (0, 0, 255)\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            font_thickness = 1\n",
    "            text_size, _ = cv2.getTextSize(custom_text, font, font_scale, font_thickness)\n",
    "            text_x = x1\n",
    "            text_y = y1 - 10 if y1 - 10 > 10 else y1 + text_size[1] + 10\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, custom_text, (text_x, text_y), font, font_scale, color, font_thickness)\n",
    "    return tracker_d, output"
   ],
   "metadata": {
    "id": "lU56DUSI6Has"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "path = \"/content/drive/MyDrive/Проекты/apples\"\n",
    "detection_model = YOLO('/content/tracker.pt')\n",
    "classification_model = YOLO('/content/classification.pt')\n",
    "video = cv2.VideoCapture(f\"{path}/Apples_class.mp4\")\n",
    "\n",
    "# Настройка выходного видео\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "output_file = f'{path}/Yolo_tracker.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_file, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "# Директория для сохранения вырезанных объектов\n",
    "save_dir = f'cut_apples'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "start = time.time()\n",
    "frame_count = 0\n",
    "tracker_d = {}\n",
    "while frame_count < 300:\n",
    "    if frame_count % 20 == 0:\n",
    "        end_local = time.time()\n",
    "        print(frame_count, f'mean_time = {(end_local - start)  / (frame_count + 1)}')\n",
    "    frame_count += 1\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Применяем модель YOLO для детекции объектов\n",
    "    results = detection_model.track(frame, persist=True, conf=0.3)\n",
    "    tracker_d, output = draw_custom_annotations(frame, results, tracker_d, save_dir, frame_count)\n",
    "\n",
    "    # Записываем кадр в выходное видео\n",
    "    out.write(frame)\n",
    "    for i in output:\n",
    "        line = tracker_d[i]['general']['line']\n",
    "        general_sum_bad = tracker_d[i]['general']['sum_bad']\n",
    "        general_count = tracker_d[i]['general']['count']\n",
    "        general_sum_D = tracker_d[i]['general']['sum_D']\n",
    "        general_sum_median_h = tracker_d[i]['general']['sum_median_h']\n",
    "\n",
    "        text = f\"Яблоко {int(i)} вышло на {line} линии!\\n\" + ' ' * 4\n",
    "        text += f\"Плохое в {general_sum_bad}/{general_count} ({round(100 * general_sum_bad / general_count)}%) кадрах\\n\" + ' ' * 4\n",
    "        text += f\"Средний диаметр - {round(general_sum_D / general_count, 2)}\\n\" + ' ' * 4\n",
    "        text += f\"Средний h - {round(general_sum_median_h / general_count, 2)}\\n\" + ' ' * 4\n",
    "\n",
    "        print(text)\n",
    "\n",
    "end = time.time()\n",
    "video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"\\nTime - {(end - start) / frame_count}\")"
   ],
   "metadata": {
    "id": "ZWYMzWzX6M5R"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
